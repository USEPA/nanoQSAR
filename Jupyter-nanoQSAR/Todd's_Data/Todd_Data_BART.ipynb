{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script performs the Bayesian Additive Regression Trees analysis on Todd Martin's data.\n",
    "#\n",
    "# Created: 01/19/2018 Wilson Melendez\n",
    "# Revised: \n",
    "\n",
    "# Set location of main scripts.  The user has to adjust this pathname based on the location where this and \n",
    "# other scripts are located.\n",
    "working_directory <- getwd()\n",
    "\n",
    "# Set working directory\n",
    "setwd(working_directory)\n",
    "\n",
    "# Set pathname of location of Todd's data. \n",
    "toddFolder <- working_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/usr/lib/jvm/java-8-openjdk-amd64/'"
      ],
      "text/latex": [
       "'/usr/lib/jvm/java-8-openjdk-amd64/'"
      ],
      "text/markdown": [
       "'/usr/lib/jvm/java-8-openjdk-amd64/'"
      ],
      "text/plain": [
       "[1] \"/usr/lib/jvm/java-8-openjdk-amd64/\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine now using 4 cores.\n"
     ]
    }
   ],
   "source": [
    "# Set JAVA_HOME to the location of the JDK in your system.\n",
    "# Sys.setenv(\"JAVA_HOME\"=\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_152\")\n",
    "\n",
    "#  Get the location of the JDK\n",
    "Sys.getenv(\"JAVA_HOME\")\n",
    "\n",
    "# Load the rJava package -- this is needed by the bartMachine.\n",
    "library(rJava)\n",
    "\n",
    "# Load the tictoc library\n",
    "library(tictoc)\n",
    "\n",
    "# Allocate memory needed before loading the bartMachine.\n",
    "# Note that the maximum amount of memory can be set only once at the beginning of the R session (a\n",
    "# limitation of rJava since only one Java Virtual Machine can be initiated per R session), but the number of\n",
    "# cores can be respecified at any time.\n",
    "options(java.parameters = \"-Xmx16g\")\n",
    "\n",
    "# Load the bartMachine package.\n",
    "library(bartMachine)\n",
    "\n",
    "# Allocate number of cores that will be used by the bartMachine.\n",
    "set_bart_machine_num_cores(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the names of the files to the directory pathanme.\n",
    "filename1 <- paste(toddFolder, \"/LC50_training_set-2d.csv\", sep = \"\")\n",
    "filename2 <- paste(toddFolder, \"/LC50_prediction_set-2d.csv\", sep = \"\")\n",
    "\n",
    "# Read in CSV files.\n",
    "Todd_TrainingData <- read.csv(filename1, stringsAsFactors=FALSE)\n",
    "Todd_TestData <- read.csv(filename2, stringsAsFactors=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the training X and Y matrices \n",
    "Xtraining <- Todd_TrainingData\n",
    "Xtraining$CAS <- NULL\n",
    "Xtraining$Tox <- NULL\n",
    "Ytraning <- Todd_TrainingData$Tox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any non-numeric column of the X matrix to numeric.\n",
    "numCols = ncol(Xtraining)   # Get the number of columns.\n",
    "for (i in 1:numCols)\n",
    "{\n",
    "  if (class(Xtraining[,i]) != \"numeric\")\n",
    "  {\n",
    "    Xtraining[,i] <- as.numeric(Xtraining[,i])\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the X and Y test matrices.\n",
    "Xtest <- Todd_TestData\n",
    "Xtest$CAS <- NULL\n",
    "Xtest$Tox <- NULL\n",
    "Ytest <- Todd_TestData$Tox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any non-numeric column of the X test matrix to numeric.\n",
    "numCols = ncol(Xtest)  # Get the number of columns\n",
    "for (i in 1:numCols)\n",
    "{\n",
    "  if (class(Xtest[,i]) != \"numeric\")\n",
    "  {\n",
    "    Xtest[,i] <- as.numeric(Xtest[,i])\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine initializing with 200 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 798 total features...\n",
      "warning: cannot use MSE of linear model for s_sq_y if p > n. bartMachine will use sample var(y) instead.\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for regression ...\n",
      "evaluating in sample data...done\n",
      "BartMachine with Default Parameters: 12.588 sec elapsed\n",
      "[1] \"BartMachine with Default Parameters: 12.588 sec elapsed\"\n"
     ]
    }
   ],
   "source": [
    "tic.clearlog()\n",
    "tic(msg = \"BartMachine with Default Parameters\")\n",
    "# Build a BART model using default values.\n",
    "bart_machine_todd <- bartMachine(Xtraining, Ytraning, \n",
    "                                 num_trees = 200,\n",
    "                                 num_burn_in = 250,\n",
    "                                 num_iterations_after_burn_in = 1000,\n",
    "                                 alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3,\n",
    "                                 prob_rule_class = 0.5,\n",
    "                                 mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
    "                                 debug_log = FALSE,\n",
    "                                 run_in_sample = TRUE,\n",
    "                                 s_sq_y = \"mse\",\n",
    "                                 sig_sq_est = NULL,\n",
    "                                 cov_prior_vec = NULL,\n",
    "                                 use_missing_data = FALSE, \n",
    "                                 covariates_to_permute = NULL,\n",
    "                                 num_rand_samps_in_library = 10000,\n",
    "                                 use_missing_data_dummies_as_covars = FALSE,\n",
    "                                 replace_missing_data_with_x_j_bar = FALSE,\n",
    "                                 impute_missingness_with_rf_impute = FALSE,\n",
    "                                 impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
    "                                 mem_cache_for_speed = TRUE,\n",
    "                                 serialize = FALSE,\n",
    "                                 seed = NULL,\n",
    "                                 verbose = TRUE)\n",
    "                            \n",
    "toc(log = TRUE)\n",
    "log.txt <- tic.log(format = TRUE)\n",
    "print(unlist(log.txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine v1.2.3 for regression\n",
      "\n",
      "training data n = 659 and p = 797 \n",
      "built in 10.5 secs on 4 cores, 200 trees, 250 burn-in and 1000 post. samples\n",
      "\n",
      "sigsq est for y beforehand: 2.237 \n",
      "avg sigsq estimate after burn-in: 0.37366 \n",
      "\n",
      "in-sample statistics:\n",
      " L1 = 233 \n",
      " L2 = 151.22 \n",
      " rmse = 0.48 \n",
      " Pseudo-Rsq = 0.8973\n",
      "p-val for shapiro-wilk test of normality of residuals: 0 \n",
      "p-val for zero-mean noise: 0.95758 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a summary of the results.\n",
    "summary(bart_machine_todd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training data. Note: this is not necessary in this case because the bart_machine_todd\n",
    "# object has predicted values stored in it.  Consider this an example on how to use the \"predict\" function.\n",
    "y_pred_training <- predict(bart_machine_todd, Xtraining)\n",
    "\n",
    "# Save bartMachine object in a file.\n",
    "saveRDS(bart_machine_todd, file = \"bart_machine.todd.rds\")\n",
    "\n",
    "# Save predicted training values to a CSV file.\n",
    "df_training <- data.frame(Ytraning, y_pred_training)\n",
    "write.csv(df_training, \"Predicted_Training_Values_JN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.7383556\n",
      "[1] 0.7461869\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data.  \n",
    "y_pred_test <- predict(bart_machine_todd, Xtest)\n",
    "\n",
    "# Write predicted values to a file.\n",
    "saveRDS(y_pred_test, file = \"PredictedValues_Todd_TestData.rds\")\n",
    "\n",
    "# Save predicted test values to a CSV file.\n",
    "df_test <- data.frame(Ytest, y_pred_test)\n",
    "write.csv(df_test, \"Predicted_Test_Values_JN.csv\")\n",
    "\n",
    "# We can test model performance on out-of-sample test data for which the outcomes are known.  \n",
    "oos_perf <- bart_predict_for_test_data(bart_machine_todd, Xtest, Ytest)\n",
    "print(oos_perf$rmse)  # Print the root-mean-square error\n",
    "\n",
    "# Calculate Q2 using the Java program's formula.\n",
    "Q2 = 1.0 - sum((Ytest - y_pred_test)^2) / sum((Ytest - mean(Ytest))^2)\n",
    "print(Q2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
