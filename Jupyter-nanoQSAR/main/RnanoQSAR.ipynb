{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script performs a Bayesian Additive Regression Trees analysis of the nanoQSAR data.\n",
    "#\n",
    "# Created: 01/02/2018 Wilson Melendez\n",
    "# Revised: \n",
    "\n",
    "# Set the location of scripts.\n",
    "working_directory <- getwd()\n",
    "\n",
    "# Set working directory\n",
    "setwd(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load external functions into this script.\n",
    "source(\"runJarFile.R\")\n",
    "source(\"extractNumericColumns.R\")\n",
    "source(\"extractXcolumns.R\")\n",
    "source(\"extractYcolumn.R\")\n",
    "source(\"getRecordswithResults.R\")\n",
    "source(\"removeColumnsWithAllNAs.R\")\n",
    "source(\"removeColumnsWithOneRepeatedValue.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_152'"
      ],
      "text/latex": [
       "'C:\\textbackslash{}\\textbackslash{}Program Files\\textbackslash{}\\textbackslash{}Java\\textbackslash{}\\textbackslash{}jdk1.8.0\\_152'"
      ],
      "text/markdown": [
       "'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_152'"
      ],
      "text/plain": [
       "[1] \"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_152\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define string with location of Jar File\n",
    "jarFolder <- working_directory\n",
    "\n",
    "# Call function that will run Jar file.\n",
    "runJarFile(jarFolder)\n",
    "\n",
    "# Read in CSV file.\n",
    "filename <- paste(jarFolder, \"/nanoQSAR.csv\", sep=\"\")\n",
    "nanoQSARdata <- read.csv(filename, stringsAsFactors=FALSE)\n",
    "\n",
    "# Extract numeric columns\n",
    "numericData <- extractNumericColumns(nanoQSARdata)\n",
    "\n",
    "# Get the records with results\n",
    "trainingData <- getRecordswithResults(numericData)\n",
    "\n",
    "# Extract the X matrix.\n",
    "XmatrixOrig <- extractXcolumns(trainingData)\n",
    "\n",
    "# Extract results column.\n",
    "Ymatrix <- extractYcolumn(trainingData)\n",
    "\n",
    "# Convert Y matrix to numeric \n",
    "y = as.numeric(Ymatrix)\n",
    "\n",
    "# Check whether the X matrix has columns with no values (all NAs), and if so remove those columns.\n",
    "Xmatrix <- removeColumnsWithAllNAs(XmatrixOrig)\n",
    "\n",
    "# Check whether the X matrix has columns with only a single value that is repeated throughout the column.\n",
    "Xmatrix <- removeColumnsWithOneRepeatedValue(Xmatrix)\n",
    "\n",
    "# Set JAVA_HOME to the location of the JDK in your system.\n",
    "Sys.setenv(\"JAVA_HOME\"=\"C:\\\\Program Files\\\\Java\\\\jdk1.8.0_152\")\n",
    "\n",
    "#  Get the location of the JDK\n",
    "Sys.getenv(\"JAVA_HOME\")\n",
    "\n",
    "# Load the rJava package -- this is needed by the bartMachine.\n",
    "library(rJava)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: bartMachineJARs\n",
      "Loading required package: car\n",
      "Loading required package: carData\n",
      "Loading required package: randomForest\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "Loading required package: missForest\n",
      "Loading required package: foreach\n",
      "Loading required package: itertools\n",
      "Loading required package: iterators\n",
      "Welcome to bartMachine v1.2.3! You have 2.8GB memory available.\n",
      "\n",
      "If you run out of memory, restart R, and use e.g.\n",
      "'options(java.parameters = \"-Xmx5g\")' for 5GB of RAM before you call\n",
      "'library(bartMachine)'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine now using 4 cores.\n",
      "bartMachine initializing with 200 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 55 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for regression ...Missing data feature ON. Missingness used as covariates. \n",
      "evaluating in sample data...done\n",
      "serializing in order to be saved for future R sessions...done\n",
      "bartMachine v1.2.3 for regression\n",
      "\n",
      "Missing data feature ON\n",
      "training data n = 250 and p = 54 \n",
      "built in 11.7 secs on 4 cores, 200 trees, 250 burn-in and 1000 post. samples\n",
      "\n",
      "sigsq est for y beforehand: 340.801 \n",
      "avg sigsq estimate after burn-in: 191.19108 \n",
      "\n",
      "in-sample statistics:\n",
      " L1 = 2200.69 \n",
      " L2 = 42221.04 \n",
      " rmse = 13 \n",
      " Pseudo-Rsq = 0.785\n",
      "p-val for shapiro-wilk test of normality of residuals: 0 \n",
      "p-val for zero-mean noise: 0.87368 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate memory needed before loading the bartMachine.\n",
    "# Note that the maximum amount of memory can be set only once at the beginning of the R session (a\n",
    "# limitation of rJava since only one Java Virtual Machine can be initiated per R session), but the number of\n",
    "# cores can be respecified at any time.\n",
    "options(java.parameters = \"-Xmx3000m\")\n",
    "\n",
    "# Load the bartMachine package\n",
    "library(bartMachine)\n",
    "\n",
    "# Allocate number of cores that will be used by the bartMachine\n",
    "set_bart_machine_num_cores(4)\n",
    "\n",
    "# Call the bartMachine\n",
    "bart_machine <- bartMachine(Xmatrix, y, \n",
    "                            num_trees = 200,\n",
    "                            num_burn_in = 250,\n",
    "                            num_iterations_after_burn_in = 1000,\n",
    "                            alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3,\n",
    "                            prob_rule_class = 0.5,\n",
    "                            mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
    "                            debug_log = FALSE,\n",
    "                            run_in_sample = TRUE,\n",
    "                            s_sq_y = \"mse\",\n",
    "                            sig_sq_est = NULL,\n",
    "                            cov_prior_vec = NULL,\n",
    "                            use_missing_data = TRUE, \n",
    "                            covariates_to_permute = NULL,\n",
    "                            num_rand_samps_in_library = 10000,\n",
    "                            use_missing_data_dummies_as_covars = TRUE,\n",
    "                            replace_missing_data_with_x_j_bar = FALSE,\n",
    "                            impute_missingness_with_rf_impute = FALSE,\n",
    "                            impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
    "                            mem_cache_for_speed = TRUE,\n",
    "                            serialize = TRUE,\n",
    "                            seed = NULL,\n",
    "                            verbose = TRUE)\n",
    "\n",
    "# Print a summary of the results, which includes R2.\n",
    "summary(bart_machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....\n",
      "[1] 0.6109627\n",
      "[1] 17.48078\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the training data. Note: this is not necessary in this case because the bart_machine\n",
    "# object does provide predicted values.  Consider this an example on how to use the \"predict\" function.\n",
    "y_hat <- predict(bart_machine, Xmatrix)\n",
    "\n",
    "# Perform k-fold cross validation using default values.\n",
    "bart_machine_cv5fold <- k_fold_cv(Xmatrix, y, \n",
    "                                  k_folds = 5,\n",
    "                                  folds_vec = NULL, \n",
    "                                  verbose = FALSE, \n",
    "                                  num_trees = 200,\n",
    "                                  num_burn_in = 250,\n",
    "                                  num_iterations_after_burn_in = 1000,\n",
    "                                  alpha = 0.95, beta = 2, k = 2, q = 0.9, nu = 3,\n",
    "                                  prob_rule_class = 0.5,\n",
    "                                  mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
    "                                  use_missing_data = TRUE, \n",
    "                                  use_missing_data_dummies_as_covars = TRUE,\n",
    "                                  serialize = TRUE)\n",
    "\n",
    "# Print R2 and RMSE values.\n",
    "print(bart_machine_cv5fold$PseudoRsq)\n",
    "print(bart_machine_cv5fold$rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bartMachine CV try: k: 2 nu, q: 3, 0.9 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 2 nu, q: 3, 0.9 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 2 nu, q: 3, 0.99 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 2 nu, q: 3, 0.99 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 2 nu, q: 10, 0.75 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 2 nu, q: 10, 0.75 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 3 nu, q: 3, 0.9 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 3 nu, q: 3, 0.9 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 3 nu, q: 3, 0.99 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 3 nu, q: 3, 0.99 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 3 nu, q: 10, 0.75 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 3 nu, q: 10, 0.75 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 5 nu, q: 3, 0.9 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 5 nu, q: 3, 0.9 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 5 nu, q: 3, 0.99 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 5 nu, q: 3, 0.99 m: 200 \n",
      ".....\n",
      "  bartMachine CV try: k: 5 nu, q: 10, 0.75 m: 50 \n",
      ".....\n",
      "  bartMachine CV try: k: 5 nu, q: 10, 0.75 m: 200 \n",
      ".....\n",
      "  bartMachine CV win: k: 2 nu, q: 10, 0.75 m: 50 \n",
      "bartMachine initializing with 50 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 55 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for regression ...Missing data feature ON. Missingness used as covariates. \n",
      "evaluating in sample data...done\n",
      "serializing in order to be saved for future R sessions...done\n",
      "      k nu    q num_trees oos_error % diff with lowest\n",
      " [1,] 2 10 0.75        50  13.70280           0.000000\n",
      " [2,] 2  3 0.99        50  14.26310           4.088917\n",
      " [3,] 2  3 0.90        50  14.44024           5.381643\n",
      " [4,] 3  3 0.90        50  15.49381          13.070418\n",
      " [5,] 3  3 0.99        50  15.56046          13.556760\n",
      " [6,] 3 10 0.75        50  16.00878          16.828545\n",
      " [7,] 2  3 0.90       200  17.07444          24.605461\n",
      " [8,] 2 10 0.75       200  17.24986          25.885639\n",
      " [9,] 2  3 0.99       200  17.32237          26.414813\n",
      "[10,] 5 10 0.75        50  19.90136          45.235701\n",
      "[11,] 3  3 0.90       200  20.01532          46.067403\n",
      "[12,] 5  3 0.90        50  20.01561          46.069503\n",
      "[13,] 5  3 0.99        50  20.05662          46.368790\n",
      "[14,] 3 10 0.75       200  20.06521          46.431449\n",
      "[15,] 3  3 0.99       200  20.12551          46.871499\n",
      "[16,] 5 10 0.75       200  23.60180          72.240669\n",
      "[17,] 5  3 0.99       200  23.66424          72.696378\n",
      "[18,] 5  3 0.90       200  23.74251          73.267573\n"
     ]
    }
   ],
   "source": [
    "# Build a BART-CV model by cross-validating over a grid of hyperparameter choices.\n",
    "# Warning: this can take a long time to run.\n",
    "# bartMachine CV win: k: 2 nu, q: 3, 0.99 m: 50\n",
    "bart_machine_CV <- bartMachineCV(Xmatrix, y,\n",
    "                                 num_tree_cvs = c(50, 200), \n",
    "                                 k_cvs = c(2, 3, 5),\n",
    "                                 nu_q_cvs = list(c(3, 0.9), c(3, 0.99), c(10, 0.75)), \n",
    "                                 k_folds = 5, verbose = FALSE,\n",
    "                                 num_burn_in = 250,\n",
    "                                 num_iterations_after_burn_in = 1000,\n",
    "                                 alpha = 0.95, beta = 2,\n",
    "                                 prob_rule_class = 0.5,\n",
    "                                 mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
    "                                 use_missing_data = TRUE, \n",
    "                                 use_missing_data_dummies_as_covars = TRUE,\n",
    "                                 serialize = TRUE)\n",
    "              \n",
    "# Print statistics\n",
    "print(bart_machine_CV$cv_stats)\n",
    "\n",
    "# Save model to a file.\n",
    "saveRDS(bart_machine_CV, file = \"bart_machine_CV.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bartMachine initializing with 200 trees...\n",
      "bartMachine vars checked...\n",
      "bartMachine java init...\n",
      "bartMachine factors created...\n",
      "bartMachine before preprocess...\n",
      "bartMachine after preprocess... 55 total features...\n",
      "bartMachine sigsq estimated...\n",
      "bartMachine training data finalized...\n",
      "Now building bartMachine for regression ...Missing data feature ON. Missingness used as covariates. \n",
      "evaluating in sample data...done\n",
      "serializing in order to be saved for future R sessions...done\n",
      "bartMachine v1.2.3 for regression\n",
      "\n",
      "Missing data feature ON\n",
      "training data n = 250 and p = 54 \n",
      "built in 7.4 secs on 4 cores, 200 trees, 250 burn-in and 1000 post. samples\n",
      "\n",
      "sigsq est for y beforehand: 340.801 \n",
      "avg sigsq estimate after burn-in: 166.52864 \n",
      "\n",
      "in-sample statistics:\n",
      " L1 = 1999.57 \n",
      " L2 = 35577.83 \n",
      " rmse = 11.93 \n",
      " Pseudo-Rsq = 0.8188\n",
      "p-val for shapiro-wilk test of normality of residuals: 0 \n",
      "p-val for zero-mean noise: 0.94533 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run a new bartMachine case by reducing beta: this will add more levels to the trees (deeper trees).\n",
    "bart_machine1 <- bartMachine(Xmatrix, y, \n",
    "                            num_trees = 200,\n",
    "                            num_burn_in = 250,\n",
    "                            num_iterations_after_burn_in = 1000,\n",
    "                            alpha = 0.95, beta = 1, k = 2, q = 0.9, nu = 3,\n",
    "                            prob_rule_class = 0.5,\n",
    "                            mh_prob_steps = c(2.5, 2.5, 4)/9,\n",
    "                            debug_log = FALSE,\n",
    "                            run_in_sample = TRUE,\n",
    "                            s_sq_y = \"mse\",\n",
    "                            sig_sq_est = NULL,\n",
    "                            cov_prior_vec = NULL,\n",
    "                            use_missing_data = TRUE, \n",
    "                            covariates_to_permute = NULL,\n",
    "                            num_rand_samps_in_library = 10000,\n",
    "                            use_missing_data_dummies_as_covars = TRUE,\n",
    "                            replace_missing_data_with_x_j_bar = FALSE,\n",
    "                            impute_missingness_with_rf_impute = FALSE,\n",
    "                            impute_missingness_with_x_j_bar_for_lm = TRUE,\n",
    "                            mem_cache_for_speed = TRUE,\n",
    "                            serialize = TRUE,\n",
    "                            seed = NULL,\n",
    "                            verbose = TRUE)  \n",
    "\n",
    "summary(bart_machine1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bartMachine objects to files.  The saveRDS function saves only an object at a time.\n",
    "# Use readRDS() to load the objects back into R.\n",
    "saveRDS(bart_machine, file = \"bart_machine.rds\")\n",
    "saveRDS(bart_machine_cv5fold, file = \"bart_machine_cv5fold.rds\")\n",
    "saveRDS(bart_machine1, file = \"bart_machine_DeeperTrees.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
